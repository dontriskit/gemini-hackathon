we are currently working on our projects for https://cerebralvalley.ai/e/2025-ted-ai-hackathon hackathon.

Hackathon theme = "Agentic Multimodal Applications, with problem statements across camera integration, whiteboard problem solving, and live slide analysis."

## **Problem Statement**

This year’s hackathon will use **Google Gemini as the base model**, giving participants direct access to one of the most advanced multimodal AI systems available today. The theme is **Multimodal Agents** (see Sample Projects for examples). The goal is to develop a solution that uses Gemini as a foundation and layers additional functionality, integrations, or experiences on top of it. This could mean:

- Creating new tools, apps, or services powered by Gemini’s APIs.

- Combining Gemini with external systems (databases, sensors, workflows, etc.).

- Designing extensions that make Gemini more useful, scalable, or domain-specific.

### **✅ Sample Projects for Multimodal Agents**

- Realtime voice copilot that watches a live camera feed and operates desktop apps to complete tasks (e.g., “file this invoice, update the CRM, email a receipt”), with human approval gates on risky actions.

- Chart and diagram tutor that explains multi‑step STEM problems from photos of whiteboards, schematics, or lab outputs, designed against MMMU‑style reasoning difficulty.

- Multimodal meeting aide that live‑transcribes, detects action items from slides and screen shares, and files tickets or calendar events with human‑in‑the‑loop.

- Red-teaming agent that automatically finds and exploits CVEs.

